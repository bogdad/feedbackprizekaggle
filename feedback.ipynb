{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37f1ec41-ecf0-41c8-a316-ce90f5e29bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_model_inproc(model_fold_storage, problem_type, model_type, X, y, Xtest):\n",
    "    import os\n",
    "    print(\"kfold\", str(os.getpid()))\n",
    "    import tensorflow as tf\n",
    "    from keras import backend as K\n",
    "    import gc\n",
    "    from tqdm import tqdm\n",
    "    import numpy as np\n",
    "    split = 5\n",
    "    global pred_dim\n",
    "    global pred_dim_list\n",
    "    pred_dim_list = [i if i>0 else X.shape[0] for i in problem_type.pred_dim()]\n",
    "    pred_dim = tuple(i for i in pred_dim_list)\n",
    "    global oof_pred\n",
    "    oof_pred = np.zeros(pred_dim)\n",
    "    global test_pred\n",
    "    test_pred_dim_list = [i if i>0 else Xtest.shape[0] for i in problem_type.pred_dim()]\n",
    "    test_pred_dim = tuple(i for i in test_pred_dim_list)\n",
    "    test_pred = np.zeros((split,) + test_pred_dim)\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    kf = StratifiedKFold(n_splits=split, shuffle=True)\n",
    "    i_fold=0\n",
    "    all_train_idx = []\n",
    "    all_valid_idx = []\n",
    "    all_model_files = []\n",
    "    global all_metrics\n",
    "    all_metrics = {}\n",
    "    global train_idx\n",
    "    global valid_idx\n",
    "    for train_idx, valid_idx in tqdm(kf.split(X, y.argmax(1))):\n",
    "        all_train_idx.append(train_idx)\n",
    "        all_valid_idx.append(valid_idx)\n",
    "    nfolds = len(all_valid_idx)\n",
    "    for i_fold in range(nfolds):\n",
    "        train_idx = all_train_idx[i_fold]\n",
    "        valid_idx = all_valid_idx[i_fold]\n",
    "        Xt = X.iloc[train_idx]\n",
    "        yt = y[train_idx]\n",
    "        Xv = X.iloc[valid_idx]\n",
    "        yv = y[valid_idx]\n",
    "        \n",
    "        model, model_files = model_fold_storage.try_load_model(model_type, i_fold)\n",
    "        if model is None:\n",
    "            model = model_type.create()\n",
    "            model_type.fit(model, Xt, yt, Xv, yv)\n",
    "            model_files = model_fold_storage.save_model(model_type, i_fold, model)\n",
    "        \n",
    "        global oof_df_fold\n",
    "        oof_df_fold = model_type.predict(model, Xv)\n",
    "        global metrics\n",
    "        metrics = model_type.evaluate(model, Xv, yv)\n",
    "        for key in metrics:\n",
    "            if key in all_metrics:\n",
    "                all_metrics[key]=np.hstack((all_metrics[key], metrics[key]))\n",
    "            else: \n",
    "                all_metrics[key]=metrics[key]\n",
    "        global test_df_fold\n",
    "        test_df_fold = model_type.predict(model, Xtest)\n",
    "        model_fold_storage.save_fold(model_type, X, y, valid_idx, train_idx, i_fold, oof_df_fold, test_df_fold, metrics)\n",
    "        \n",
    "        oof_pred[valid_idx, :] = np.reshape(oof_df_fold, oof_df_fold.shape)\n",
    "        test_pred[i_fold]=test_df_fold\n",
    "        all_model_files.append(model_files)\n",
    "        i_fold+=1\n",
    "        K.clear_session()\n",
    "        del model\n",
    "        gc.collect()\n",
    "        K.clear_session()\n",
    "        gc.collect()\n",
    "        K.clear_session()\n",
    "    model_fold_storage.save_kfold(model_type, X, y, all_valid_idx, all_train_idx, all_model_files, oof_pred, test_pred, all_metrics)\n",
    "    return oof_pred, test_pred, all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8350b36e-d7fd-48ec-9edb-bf7620abf27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file models already exists.\n"
     ]
    }
   ],
   "source": [
    "!mkdir kfold_models\n",
    "!mkdir fold_models\n",
    "!mkdir models\n",
    "!mkdir tar_models\n",
    "class ModelFoldStorage:\n",
    "    def save_fold(self, model_type, X, y, valid_idx, train_idx, i_fold, oof_df_fold, test_df_fold, metrics):\n",
    "        import pickle\n",
    "        foldData = {}\n",
    "        foldData['X'], foldData['y'],foldData['valid_idx'],foldData['train_idx']=X,y,valid_idx,train_idx\n",
    "        foldData['oof_df_fold'],foldData['i_fold'], foldData['metrics'], foldData['test_df_fold']=oof_df_fold,i_fold, metrics, test_df_fold\n",
    "        with open(r\"fold_models/\"+model_type.name()+\"_\"+str(i_fold)+\"_fold.bin\", \"wb\") as output_file:\n",
    "            pickle.dump(foldData, output_file)\n",
    "    def try_load_kfold(self, model_type):\n",
    "        import pickle\n",
    "        with open(r\"kfold_models/\"+model_type.name()+\"_kfold.bin\", \"rb\") as input_file:\n",
    "            modelTypeData = pickle.read(input_file)\n",
    "            return modelTypeData['oof_pred'], modelTypeData['test_pred'], modelTypeData['all_metrics']\n",
    "        return None\n",
    "    def save_kfold(self, model_type, X, y, all_valid_idx, all_train_idx, all_model_files, oof_pred, test_pred, all_metrics):\n",
    "        import pickle\n",
    "        modelTypeData = {}\n",
    "        modelTypeData['X'], modelTypeData['y'],modelTypeData['all_valid_idx'],modelTypeData['all_train_idx'], modelTypeData['all_model_files']=X,y,all_valid_idx,all_train_idx, all_model_files\n",
    "        modelTypeData['model_type'], modelTypeData['oof_pred'],modelTypeData['all_metrics'], modelTypeData['test_pred']=model_type, oof_pred, all_metrics, test_pred\n",
    "        with open(r\"kfold_models/\"+model_type.name()+\"_kfold.bin\", \"wb\") as output_file:\n",
    "            pickle.dump(modelTypeData, output_file)\n",
    "    def save_model(self, model_type, i_fold, model):\n",
    "        file = r\"models/\"+model_type.name()+\"_\"+str(i_fold)+\"_model\"\n",
    "        files = model_type.save(file, model)\n",
    "        files = self.tar(file, files)\n",
    "        print(\"saved model %s to %s (%s)\" % (model_type.name(), file, \", \".join(files)))\n",
    "        return files\n",
    "    def try_load_model(self, model_type, i_fold):\n",
    "        file = r\"models/\"+model_type.name()+\"_\"+str(i_fold)+\"_model\"\n",
    "        file = self.try_untar(file)\n",
    "        model, model_files = model_type.load(file)\n",
    "        if model is None:\n",
    "            print(\"could not load model %s from %s\" % (model_type.name(), file))\n",
    "        else:\n",
    "            print(\"loaded model %s from %s\" % (model_type.name(), file))\n",
    "        return model, model_files\n",
    "    def tar(self, file, files):\n",
    "        import tarfile\n",
    "        tar = \"tar_\"+file + \".tar.gz.xyz\"\n",
    "        with tarfile.open(tar, \"w:gz\") as tar:\n",
    "            for f in files:\n",
    "                tar.add(f, arcname=os.path.basename(f))\n",
    "        files.append(tar)\n",
    "        return files\n",
    "    def try_untar(self, file):\n",
    "        import pathlib\n",
    "        import tensorflow as tf\n",
    "        import os\n",
    "        import tarfile\n",
    "        file_gz = \"tar_\"+file + \".tar.gz.xyz\"\n",
    "        filepath = pathlib.PurePath(file)\n",
    "        file_name = filepath.name\n",
    "        if not os.path.exists(file) and os.path.exists(file_gz):\n",
    "            import atexit, shutil, tempfile\n",
    "            models_dir = tempfile.mkdtemp()\n",
    "            atexit.register(shutil.rmtree, models_dir)\n",
    "            if not models_dir.endswith('/'):\n",
    "                models_dir = models_dir + '/'\n",
    "            print(\"loading from\", file_gz)\n",
    "            target_model_name = models_dir + file_name\n",
    "            with tarfile.open(file_gz) as my_tar:\n",
    "                my_tar.extractall(models_dir) # specify which folder to extract to\n",
    "                my_tar.close()\n",
    "            file = target_model_name\n",
    "            return file\n",
    "        return file\n",
    "    \n",
    "model_fold_storage = ModelFoldStorage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7cf4571-97f1-4e9e-adf6-5d047c41865c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyProblem:\n",
    "    def pred_dim(self):\n",
    "        return [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bab60661-66eb-4b57-bcd3-bea7eb6e6d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel:\n",
    "    def name(self):\n",
    "        pass\n",
    "    def create(self):\n",
    "        pass\n",
    "    def fit(self, model, Xt, yt, Xv, yv):\n",
    "        pass\n",
    "    def predict(self, model, Xt):\n",
    "        pass\n",
    "    def evaluate(self, model, x, y):\n",
    "        pass\n",
    "    def save(self, file, model):\n",
    "        pass\n",
    "    def load(self, file):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a23db498-ecd7-4a79-a557-69c4c5c96752",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DatasetMapFunction(input_ids, attn_masks, labels):\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attn_masks\n",
    "            }, labels\n",
    "class MyBertModel(MyModel):\n",
    "    def __init__(self, debug=False):\n",
    "        self.debug = debug\n",
    "    def create(self):\n",
    "        import tensorflow as tf\n",
    "        import tensorflow_hub as hub\n",
    "        import tensorflow_text as text\n",
    "        from transformers import TFBertModel\n",
    "        model = TFBertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        input_ids = tf.keras.layers.Input(shape=(256,), name='input_ids', dtype='int32')\n",
    "        attn_masks = tf.keras.layers.Input(shape=(256,), name='attention_mask', dtype='int32')\n",
    "\n",
    "        bert_embds = model.bert(input_ids, attention_mask=attn_masks)[1] # 0 -> activation layer (3D), 1 -> pooled output layer (2D)\n",
    "        intermediate_layer = tf.keras.layers.Dense(512, activation='relu', name='intermediate_layer')(bert_embds)\n",
    "        output_layer = tf.keras.layers.Dense(3, activation='softmax', name='output_layer')(intermediate_layer) # softmax -> calcs probs of classes\n",
    "\n",
    "        discourse_model = tf.keras.Model(inputs=[input_ids, attn_masks], outputs=output_layer)\n",
    "        discourse_model.summary()\n",
    "        from tensorflow.keras.optimizers import Adam\n",
    "        discourse_model.compile(optimizer=Adam(learning_rate=1e-5, decay=1e-6), \n",
    "                        loss='categorical_crossentropy', \n",
    "                        metrics=['accuracy'])\n",
    "        return (discourse_model, self, model)\n",
    "    def name(self):\n",
    "        return \"bert\"\n",
    "    def fit(self, model, Xt, yt, Xv, yv):\n",
    "        X_input_ids, X_attn_masks, yt = self._transform(Xt, yt)\n",
    "        import tensorflow as tf\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((X_input_ids, X_attn_masks, yt))\n",
    "        dataset = dataset.map(DatasetMapFunction)     # converting to required format for tensorflow dataset\n",
    "        dataset = dataset.shuffle(10000).batch(16, drop_remainder=True) # batch size, drop any left out tensor\n",
    "        X_val_input_ids, X_val_attn_masks, yv = self._transform(Xv, yv)\n",
    "        val_dataset = tf.data.Dataset.from_tensor_slices((X_val_input_ids, X_val_attn_masks, yv))\n",
    "        val_dataset = val_dataset.map(DatasetMapFunction)     # converting to required format for tensorflow dataset\n",
    "        val_dataset = val_dataset.shuffle(10000).batch(16, drop_remainder=True) # batch size, drop any left out tensor\n",
    "        epochs = 5\n",
    "        if self.debug:\n",
    "            epochs=1\n",
    "        model[1].history = model[0].fit(dataset,\n",
    "            steps_per_epoch=200,\n",
    "            validation_data=val_dataset,\n",
    "            epochs=epochs)\n",
    "    def predict(self, model, X):\n",
    "        X_test_input_ids, X_test_attn_masks, _y = self._transform(X, None)\n",
    "        labels = model[0].predict([X_test_input_ids, X_test_attn_masks])\n",
    "        return labels\n",
    "    def evaluate(self, model, x, y):\n",
    "        import tensorflow as tf\n",
    "        X_input_ids, X_attn_masks, y = self._transform(x,y)\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((X_input_ids, X_attn_masks, y))\n",
    "        dataset = dataset.map(DatasetMapFunction)\n",
    "        dataset = dataset.shuffle(10000).batch(16, drop_remainder=True)\n",
    "        return model[0].evaluate(dataset, return_dict=True)\n",
    "    def save(self, file, model):\n",
    "        import shutil\n",
    "        import os\n",
    "        import tensorflow as tf\n",
    "        import pickle\n",
    "        ttt1=file\n",
    "        tf.keras.models.save_model(model[0], ttt1)\n",
    "        ttt2=file+\"_bert\"\n",
    "        tf.keras.models.save_model(model[2], ttt2)\n",
    "        ttt3=file+\"_python\"\n",
    "        with open(ttt3, \"wb\") as output_file:\n",
    "            pickle.dump(model[1].__dict__, output_file)\n",
    "        return [ttt1, ttt2, ttt3, ttt4]\n",
    "    def load(self, file):\n",
    "        import os\n",
    "        import tensorflow as tf\n",
    "        import pickle\n",
    "        ttt1=file\n",
    "        model_0 = tf.keras.models.load_model(ttt1)\n",
    "        ttt2=file+\"_bert\"\n",
    "        model_2 = tf.keras.models.load_model(ttt2)\n",
    "        ttt3=file+\"_python\"\n",
    "        if not os.path.exists(ttt1) or not os.path.exists(ttt2) or not os.path.exists(ttt3):\n",
    "            return None, None\n",
    "        #with open(ttt3, \"rb\") as input_file:\n",
    "        #    model1_dict = pickle.load(input_file)\n",
    "        #self.__dict__.update(model1_dict)\n",
    "        model_files = [ttt1, ttt2, ttt3]\n",
    "        return (model_0, self, model_2), model_files\n",
    "    def _encode_data(self, df, ids, masks, tokenizer):\n",
    "        from tqdm.auto import tqdm\n",
    "        for i, text in tqdm(enumerate(df['text'])):\n",
    "            tokenized_text = tokenizer.encode_plus(\n",
    "                text,\n",
    "                max_length=256, \n",
    "                truncation=True, \n",
    "                padding='max_length', \n",
    "                add_special_tokens=True,\n",
    "                return_tensors='tf'\n",
    "            )\n",
    "            ids[i, :] = tokenized_text.input_ids\n",
    "            masks[i, :] = tokenized_text.attention_mask\n",
    "        return ids, masks\n",
    "    \n",
    "    def _transform(self, X,y):\n",
    "        from transformers import BertTokenizerFast\n",
    "        tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "        X[\"text\"]=X['discourse_type'] + tokenizer.sep_token+ X['text']\n",
    "        if self.debug:\n",
    "            X = X.head(1000)\n",
    "            if y is not None:\n",
    "                y = y[0:1000,:]\n",
    "        \n",
    "        import numpy as np\n",
    "        X_input_ids = np.zeros((len(X), 256))\n",
    "        X_attn_masks = np.zeros((len(X), 256))\n",
    "        from tqdm.auto import tqdm\n",
    "        X_input_ids, X_attn_masks = self._encode_data(X, X_input_ids, X_attn_masks, tokenizer)\n",
    "        return X_input_ids, X_attn_masks, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8024c639-2615-43a2-a66c-d29ab764b636",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedbackProblem(MyProblem):\n",
    "    def pred_dim(self):\n",
    "        return [0,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dce8e5d4-23aa-4d7c-8f53-966d0ed64381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_colwidth', 2550)\n",
    "df_train = pd.read_csv(\"../input/feedback-prize-effectiveness/train.csv\")\n",
    "df_test = pd.read_csv(\"../input/feedback-prize-effectiveness/test.csv\")\n",
    "df_train[\"text\"] = df_train[\"essay_id\"].apply(lambda x: open(f'../input/feedback-prize-effectiveness/train/{x}.txt').read())\n",
    "df_test[\"text\"] = df_test[\"essay_id\"].apply(lambda x: open(f'../input/feedback-prize-effectiveness/test/{x}.txt').read())\n",
    "effectiveness_map = {\"Ineffective\":0, \"Adequate\":1,\"Effective\":2}\n",
    "df_train[\"target\"] = df_train[\"discourse_effectiveness\"].map(effectiveness_map)\n",
    "labels = np.zeros((len(df_train), 3))\n",
    "labels[np.arange(len(df_train)), df_train['target'].values] = 1\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9f1961fd-1c66-424c-ac8a-f8190d345105",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_type = FeedbackProblem()\n",
    "model_type = MyBertModel(debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "faf7c83d-c830-4ebf-8587-d969517713eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold 15532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:00, 1000.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "loaded model bert from models/bert_0_model\n",
      "['.gitattributes', 'LICENSE', 'README.md', 'config.json', 'flax_model.msgpack', 'pytorch_model.bin', 'rust_model.ot', 'tf_model.h5', 'tokenizer.json', 'tokenizer_config.json', 'vocab.txt']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c1f882f5d4545b7ab4ff4ef0561044a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230/230 [==============================] - 27s 113ms/step\n",
      "['.gitattributes', 'LICENSE', 'README.md', 'config.json', 'flax_model.msgpack', 'pytorch_model.bin', 'rust_model.ot', 'tf_model.h5', 'tokenizer.json', 'tokenizer_config.json', 'vocab.txt']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ce8d1c384674720aa916c1d7bccc40f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "459/459 [==============================] - 27s 56ms/step - loss: 0.7069 - accuracy: 0.6914\n",
      "['.gitattributes', 'LICENSE', 'README.md', 'config.json', 'flax_model.msgpack', 'pytorch_model.bin', 'rust_model.ot', 'tf_model.h5', 'tokenizer.json', 'tokenizer_config.json', 'vocab.txt']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7516110f495c4662a1582e1bf9bd6f96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 186ms/step\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "loaded model bert from models/bert_1_model\n",
      "['.gitattributes', 'LICENSE', 'README.md', 'config.json', 'flax_model.msgpack', 'pytorch_model.bin', 'rust_model.ot', 'tf_model.h5', 'tokenizer.json', 'tokenizer_config.json', 'vocab.txt']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "263fdfd923114688b18ef5bf0cda9f5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230/230 [==============================] - 27s 114ms/step\n",
      "['.gitattributes', 'LICENSE', 'README.md', 'config.json', 'flax_model.msgpack', 'pytorch_model.bin', 'rust_model.ot', 'tf_model.h5', 'tokenizer.json', 'tokenizer_config.json', 'vocab.txt']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f623e10007e40b28d86460938d9845d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "459/459 [==============================] - 27s 56ms/step - loss: 0.6778 - accuracy: 0.7017\n",
      "['.gitattributes', 'LICENSE', 'README.md', 'config.json', 'flax_model.msgpack', 'pytorch_model.bin', 'rust_model.ot', 'tf_model.h5', 'tokenizer.json', 'tokenizer_config.json', 'vocab.txt']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab3b5b6c0cb74511b8cdd6dc8bb90a51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 200ms/step\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "loaded model bert from models/bert_2_model\n",
      "['.gitattributes', 'LICENSE', 'README.md', 'config.json', 'flax_model.msgpack', 'pytorch_model.bin', 'rust_model.ot', 'tf_model.h5', 'tokenizer.json', 'tokenizer_config.json', 'vocab.txt']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57906ec7a50e44f9a922cf7afdcb9545",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230/230 [==============================] - 27s 114ms/step\n",
      "['.gitattributes', 'LICENSE', 'README.md', 'config.json', 'flax_model.msgpack', 'pytorch_model.bin', 'rust_model.ot', 'tf_model.h5', 'tokenizer.json', 'tokenizer_config.json', 'vocab.txt']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d32fd6f0df9455da7f3998c98476bf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "459/459 [==============================] - 27s 56ms/step - loss: 0.7074 - accuracy: 0.6852\n",
      "['.gitattributes', 'LICENSE', 'README.md', 'config.json', 'flax_model.msgpack', 'pytorch_model.bin', 'rust_model.ot', 'tf_model.h5', 'tokenizer.json', 'tokenizer_config.json', 'vocab.txt']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65ab2bba1c3548e58a6d969b4f02d62d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 187ms/step\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "loaded model bert from models/bert_3_model\n",
      "['.gitattributes', 'LICENSE', 'README.md', 'config.json', 'flax_model.msgpack', 'pytorch_model.bin', 'rust_model.ot', 'tf_model.h5', 'tokenizer.json', 'tokenizer_config.json', 'vocab.txt']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "132a722d5889414bb94d7d3b5dcfa67a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230/230 [==============================] - 27s 114ms/step\n",
      "['.gitattributes', 'LICENSE', 'README.md', 'config.json', 'flax_model.msgpack', 'pytorch_model.bin', 'rust_model.ot', 'tf_model.h5', 'tokenizer.json', 'tokenizer_config.json', 'vocab.txt']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79d02c1ef10b47238164dc868c252068",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "459/459 [==============================] - 27s 56ms/step - loss: 0.7471 - accuracy: 0.6589\n",
      "['.gitattributes', 'LICENSE', 'README.md', 'config.json', 'flax_model.msgpack', 'pytorch_model.bin', 'rust_model.ot', 'tf_model.h5', 'tokenizer.json', 'tokenizer_config.json', 'vocab.txt']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62200b458e0e4bf68b6829880a48f96d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 233ms/step\n",
      "230/230 [==============================] - 27s 114ms/step\n",
      "['.gitattributes', 'LICENSE', 'README.md', 'config.json', 'flax_model.msgpack', 'pytorch_model.bin', 'rust_model.ot', 'tf_model.h5', 'tokenizer.json', 'tokenizer_config.json', 'vocab.txt']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ea9c2ba95274a478ba12617364d5d37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "459/459 [==============================] - 27s 56ms/step - loss: 0.7167 - accuracy: 0.6880\n",
      "['.gitattributes', 'LICENSE', 'README.md', 'config.json', 'flax_model.msgpack', 'pytorch_model.bin', 'rust_model.ot', 'tf_model.h5', 'tokenizer.json', 'tokenizer_config.json', 'vocab.txt']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65b10ac5c5504282a58452aac3191a38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 199ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0.17421667, 0.80860215, 0.01718116],\n",
       "        [0.28198764, 0.70575362, 0.01225873],\n",
       "        [0.23532078, 0.73372877, 0.03095045],\n",
       "        ...,\n",
       "        [0.10895097, 0.80916321, 0.08188581],\n",
       "        [0.3918609 , 0.58889937, 0.01923972],\n",
       "        [0.27587071, 0.6970889 , 0.02704039]]),\n",
       " array([[[0.27095884, 0.6877656 , 0.04127556],\n",
       "         [0.1978251 , 0.75418776, 0.04798716],\n",
       "         [0.16098413, 0.69339514, 0.14562067],\n",
       "         [0.54613298, 0.43652976, 0.01733723],\n",
       "         [0.34396839, 0.63820982, 0.01782181],\n",
       "         [0.39779875, 0.56405592, 0.03814538],\n",
       "         [0.44721809, 0.51481909, 0.03796284],\n",
       "         [0.3368617 , 0.62902337, 0.03411494],\n",
       "         [0.30910653, 0.63142329, 0.05947017],\n",
       "         [0.05629733, 0.39520109, 0.54850161]],\n",
       " \n",
       "        [[0.21908961, 0.76013273, 0.02077775],\n",
       "         [0.16819073, 0.80227941, 0.02952984],\n",
       "         [0.22762035, 0.67723095, 0.09514876],\n",
       "         [0.60704732, 0.38445744, 0.00849524],\n",
       "         [0.25874647, 0.70254529, 0.03870823],\n",
       "         [0.31758913, 0.6482268 , 0.0341841 ],\n",
       "         [0.46016768, 0.5210194 , 0.01881289],\n",
       "         [0.31743687, 0.66349185, 0.01907128],\n",
       "         [0.608091  , 0.38053584, 0.01137313],\n",
       "         [0.01827325, 0.36860326, 0.61312354]],\n",
       " \n",
       "        [[0.26040542, 0.70527184, 0.03432268],\n",
       "         [0.25686899, 0.71609151, 0.02703953],\n",
       "         [0.33453667, 0.62087119, 0.04459219],\n",
       "         [0.52714556, 0.456505  , 0.01634946],\n",
       "         [0.36916775, 0.61067307, 0.02015909],\n",
       "         [0.46845964, 0.50668877, 0.02485161],\n",
       "         [0.56670398, 0.41103318, 0.02226289],\n",
       "         [0.30597591, 0.64839423, 0.04562984],\n",
       "         [0.4192867 , 0.54874134, 0.03197193],\n",
       "         [0.01641698, 0.31017351, 0.67340952]],\n",
       " \n",
       "        [[0.19378765, 0.74290276, 0.06330959],\n",
       "         [0.08960348, 0.67950189, 0.23089461],\n",
       "         [0.17939068, 0.54521662, 0.27539271],\n",
       "         [0.32451975, 0.66192174, 0.01355851],\n",
       "         [0.16364828, 0.68854916, 0.14780256],\n",
       "         [0.23278485, 0.63060462, 0.13661054],\n",
       "         [0.22627886, 0.64867598, 0.12504511],\n",
       "         [0.21434899, 0.69885409, 0.08679695],\n",
       "         [0.3635326 , 0.61653888, 0.01992851],\n",
       "         [0.01430586, 0.17126068, 0.81443352]],\n",
       " \n",
       "        [[0.19784337, 0.75470012, 0.0474565 ],\n",
       "         [0.29057735, 0.68388438, 0.02553823],\n",
       "         [0.16818453, 0.63596952, 0.19584592],\n",
       "         [0.53751737, 0.45757115, 0.0049115 ],\n",
       "         [0.39146823, 0.59387183, 0.01465991],\n",
       "         [0.09471917, 0.5445227 , 0.36075813],\n",
       "         [0.42282084, 0.55605793, 0.02112122],\n",
       "         [0.35446405, 0.63014913, 0.01538683],\n",
       "         [0.51216859, 0.47941944, 0.00841198],\n",
       "         [0.01433035, 0.34017506, 0.64549464]]]),\n",
       " {'loss': array([0.70691633, 0.6777972 , 0.70738226, 0.74708688, 0.7166881 ]),\n",
       "  'accuracy': array([0.69144881, 0.70166123, 0.68518519, 0.65890521, 0.68804467])})"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold_model_inproc(model_fold_storage, problem_type, model_type, df_train, labels, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f44289a-c17d-4c0e-908d-5df59241abb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9047398-0053-4328-8e4b-b020f7131418",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
